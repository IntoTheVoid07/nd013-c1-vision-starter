{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset\n",
    "import glob\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_glob_path = \"/home/workspace/data/train/*.tfrecord\"\n",
    "dataset = get_dataset(dataset_glob_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and displays the image with \n",
    "    the associated bounding boxes.\n",
    "    \"\"\"\n",
    "    rgb_mapping = { 1: 'red',   # Vehicles\n",
    "                    2: 'green', # Cyclists\n",
    "                    4: 'blue'   # Pedestrians\n",
    "                  }\n",
    "\n",
    "    # Set the plot to show 2x5 grid of images at 36 inches each\n",
    "    # @note: Had trouble getting the workspace notebook to allow for better sizing\n",
    "    col, row = 5, 2\n",
    "    _, ax = plt.subplots(col, row, figsize=(36, 36))\n",
    "    for n, batch_data in enumerate(batch):\n",
    "        # Get the col, row position for the current image\n",
    "        x = n % col\n",
    "        y = n % row\n",
    "        # Parse out display information\n",
    "        bboxes = batch_data['groundtruth_boxes'].numpy()\n",
    "        classes = batch_data['groundtruth_classes'].numpy()\n",
    "        img = batch_data['image']\n",
    "\n",
    "        # Display the batch image\n",
    "        ax[x, y].imshow(img)\n",
    "    \n",
    "        # Normalize the bounding boxes to the current image size\n",
    "        img_height, img_width, _ = img.shape\n",
    "        normalized_bboxes = copy.deepcopy(bboxes)\n",
    "        normalized_bboxes[:, (0, 2)] = bboxes[:, (0, 2)] * img_height\n",
    "        normalized_bboxes[:, (1, 3)] = bboxes[:, (1, 3)] * img_width\n",
    "\n",
    "        # Draw the bounding box with the correct coloring based on the classification\n",
    "        # (i.e. vehicle, pedestrian, cyclist)\n",
    "        for bb, cl in zip (normalized_bboxes, classes):\n",
    "            y1, x1, y2, x2 = bb\n",
    "            anchor_point = (x1, y1)\n",
    "            bb_w =  x2 - x1\n",
    "            bb_h = y2 - y1\n",
    "            rec = patches.Rectangle(anchor_point, bb_w, bb_h, facecolor='none',\n",
    "                                    edgecolor=rgb_mapping[cl])\n",
    "            ax[x, y].add_patch(rec)\n",
    "        ax[x, y].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting shuffle buffer_size to 1000 to prevent eating up memory\n",
    "rand_dataset = dataset.shuffle(1000)\n",
    "display_instances(dataset.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The bounding boxes seem a bit off for blurrier images (due to weather). Additionally, with more objects to detect, the boxes make the image hard to see --- making it hard to detect if there's a false postive. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
